{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T15:50:14.345030Z",
     "start_time": "2020-01-28T15:50:14.058Z"
    }
   },
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(bmrm)\n",
    "library(e1071)\n",
    "library(purrr)\n",
    "library(parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Context\n",
    "\n",
    "We used Machine learning apporaches (here SVM) to show that we can distinguish between Gli1 and Ascl1 cells using\n",
    "DEG, which are common to ndNSC and dNSC, that were computed 02_differential_analysis.\n",
    "!! This script was run for 10 min in a 8CPU | 32GB RAM machine.\n",
    "\n",
    "\n",
    "\n",
    "# Function for randomly sample the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T15:50:15.913232Z",
     "start_time": "2020-01-28T15:50:15.872Z"
    }
   },
   "outputs": [],
   "source": [
    "# i.e. if Ascl1 cells in total are 62 and Gli 120, then the training set will consist of 50% Ascl = 31 and 31 of Gli\n",
    "create_dataset_train_test_randomsampling = function(df, p , seed, scale) {\n",
    "\n",
    "    # df - data.frame that contains all data\n",
    "    # p is a proportion of data to use for training (it takes the proportion of the less populated class of cells)\n",
    "    # seed - seed to sample randomly in each iteration\n",
    "    # scale - bool to indicate if to scale data or not\n",
    "    \n",
    "set.seed(seed)\n",
    "# Transpose matrix to have cells as rows\n",
    "if(any(grep(\"Ascl\", colnames(df)) == T))\n",
    "{\n",
    "    df = t(as.matrix(df))\n",
    "}\n",
    "    \n",
    "if(scale == TRUE)\n",
    "{\n",
    "    df = scale(df)\n",
    "}\n",
    "\n",
    "\n",
    "                        ### Train dataset\n",
    "    \n",
    "## Split data separately for Gli and Ascl to have the same proportion\n",
    "n_G = grep(\"Gli1\", rownames(df))\n",
    "n_A = grep(\"Ascl1\", rownames(df))\n",
    "min = min(length(n_A), length(n_G))\n",
    "\n",
    "# modify min to select the same number os cells for training\n",
    "n_Asampled = sample(n_A, size = min * p, replace = F)\n",
    "n_Gsampled = sample(n_G, size = min * p, replace = F)\n",
    "df_train = df[c(n_Asampled,n_Gsampled),]\n",
    "df_test = df[-c(n_Asampled,n_Gsampled),]\n",
    "\n",
    "    \n",
    "# Generate labels for the Gli and Ascl dataset\n",
    "vec = seq(1, nrow(df_train), 1)\n",
    "label = ifelse(vec %in% grep(\"Gli\", rownames(df_train)), \"Gli1\", \"Ascl1\") %>% as.factor\n",
    "\n",
    "                    #### Test dataset\n",
    "\n",
    "# Generate label for test dataset\n",
    "vec = seq(1, nrow(df_test), 1)\n",
    "data_test_result = ifelse(vec %in% grep(\"Gli\", rownames(df_test)), \"Gli1\", \"Ascl1\") %>% as.factor    \n",
    "\n",
    "    print(paste0(\"Total percentage of cells used for training: \", min * p * 2 / nrow(df)))\n",
    "    \n",
    "    # Print table to know the amount of cells for testing / training\n",
    "    # first entry is the number of cells used in training and 2nd entry the number of cells used in testing\n",
    "    x1 = grep(\"Gli\", rownames(df_test)) %>% length\n",
    "    x2 = grep(\"Ascl\", rownames(df_test)) %>% length\n",
    "\n",
    "    samples_Ascl1 =  c(n_Asampled %>% length,x2)\n",
    "    samples_Gli1 = c(n_Gsampled %>% length, x1)\n",
    "    df_print = data.frame(Gli = samples_Gli1, Ascl1 = samples_Ascl1)\n",
    "    rownames(df_print) = c(\"training\",\"testing\")\n",
    "    \n",
    "    print.data.frame(df_print)\n",
    "    \n",
    "    ret = list(\n",
    "        df_train = df_train,\n",
    "        df_test = df_test,\n",
    "        data_test_result = data_test_result,\n",
    "        label = label)\n",
    "    \n",
    "    return(ret)\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T15:50:27.290751Z",
     "start_time": "2020-01-28T15:50:21.709Z"
    }
   },
   "outputs": [],
   "source": [
    "load(\"../data/SO_Gli_Ascl_comb_int.Robj\")\n",
    "data_all = pbmc.combined@assays$RNA@data\n",
    "# Read the batch affected genes and take the once with p_val_adj == 0\n",
    "\n",
    "genes_dNSC = readRDS(file.path('..', 'data', 'diff_expression_dNSC.rds'))\n",
    "genes_ndNSC = readRDS(file.path('..', 'data', 'diff_expression_ndNSC.rds'))\n",
    "\n",
    "genes_model = intersect(genes_dNSC,genes_ndNSC)\n",
    "\n",
    "# Create vector with ndNSC and a vector with dNSC cells\n",
    "\n",
    "#dNSC\n",
    "x = which(pbmc.combined@meta.data$cluster == \"dNSC\")\n",
    "cells_dNSC = rownames(pbmc.combined@meta.data)[x]\n",
    "#ndNSC\n",
    "x= which(pbmc.combined@meta.data$cluster == \"ndNSC\") \n",
    "cells_ndNSC = rownames(pbmc.combined@meta.data)[x]\n",
    "cells_ndNSC_dNSC = append(cells_dNSC,cells_ndNSC)\n",
    "\n",
    "data = data_all[genes_model, cells_ndNSC_dNSC]\n",
    "\n",
    "# Check wheter we have correct data (9 330)\n",
    "dim(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with e1071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T12:53:59.823198Z",
     "start_time": "2020-01-28T12:52:15.342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use all data_pred of ascl and gli independently of the day and do random sampling\n",
    "seeds = seq(1,1000,1)\n",
    "\n",
    "# Setup cluster\n",
    "cl <- makeCluster(detectCores())\n",
    "\n",
    "# Loading all packages necesary | variables | functions\n",
    "invisible(clusterEvalQ(cl, library(\"dplyr\")))\n",
    "invisible(clusterEvalQ(cl, library(\"e1071\")))\n",
    "clusterExport(cl, c(\"create_dataset_train_test_randomsampling\"), envir = environment())\n",
    "clusterExport(cl, c(\"data\"), envir = environment())\n",
    "\n",
    "output_9_genes_svm_e1071_1000seed = parLapply(cl,seeds, function(seed) {\n",
    "    dataset_rf_randomsampling = create_dataset_train_test_randomsampling(data, 0.5, seed, scale = TRUE)\n",
    "\n",
    "\n",
    "    # Data\n",
    "    data_train = dataset_rf_randomsampling$df_train %>% data.frame\n",
    "    data_train$label = dataset_rf_randomsampling$label\n",
    "    data_test = dataset_rf_randomsampling$df_test\n",
    "    result = as.factor(dataset_rf_randomsampling$data_test_result)\n",
    "\n",
    "\n",
    "    # Tune parameter Cost\n",
    "    par_tuned = tune(\"svm\", label ~. , data = data_train, ranges = list(cost = 2^(-3:3)),\n",
    "                     tunecontrol = tune.control(sampling = \"cross\"))\n",
    "\n",
    "    # Model\n",
    "    set.seed(1)\n",
    "    svm_model <- svm(label~., data_train , cost = par_tuned$best.parameters$cost,\n",
    "                    kernel = \"linear\")\n",
    "    pred_svm <- predict(svm_model, data_test)\n",
    "    f_meas = caret::F_meas(pred_svm, result)\n",
    "    acc = mean(pred_svm == result)\n",
    "    caret::confusionMatrix(pred_svm, result)\n",
    "\n",
    "    \n",
    "    lst = list(model = svm_model,\n",
    "                    pred = pred_svm,\n",
    "                    par_tuned = par_tuned,\n",
    "                    f_meas = f_meas,\n",
    "                    acc = acc,\n",
    "                    result = result,\n",
    "                    dataset_rf_randomsampling1 = dataset_rf_randomsampling$df_test)\n",
    "    return(lst)\n",
    "})\n",
    "stopCluster(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean accuracy for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T12:54:10.542482Z",
     "start_time": "2020-01-28T12:54:11.846Z"
    }
   },
   "outputs": [],
   "source": [
    "mean(map_dbl(seq(1,length(seeds),1), function(x){output_9_genes_svm_e1071_1000seed[[x]]$acc}))\n",
    "mean(map_dbl(seq(1,length(seeds),1), function(x){output_9_genes_svm_e1071_1000seed[[x]]$f_meas}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T12:54:23.258989Z",
     "start_time": "2020-01-28T12:54:13.546Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the final Enseble scores over 1000 seeds\n",
    "output_list = output_9_genes_svm_e1071_1000seed\n",
    "\n",
    "total_cell_names = colnames(data)\n",
    "\n",
    "# Create matrices\n",
    "list_final = list(cells = total_cell_names, score = rep(0, length(total_cell_names)))\n",
    "\n",
    "# add scores (+1) to the cell that was correctly classified and (-1) otherwise\n",
    "# Loop over the seeds\n",
    "for(i in 1:length(seeds))\n",
    "{\n",
    "    true_cell_names = output_list[[i]]$dataset_rf_randomsampling1 %>% rownames \n",
    "    # Loop over each predicted cell in the model\n",
    "    for(k in 1:length(output_list[[i]]$pred))\n",
    "    {\n",
    "        cell_predicted = output_list[[i]]$pred[k]\n",
    "        cell_true = output_list[[i]]$result[k]\n",
    "            \n",
    "        # If the prediction was correct add +1 to score of this cell and -1 otherwise\n",
    "        if(cell_predicted == cell_true)\n",
    "        {\n",
    "            n = which(list_final[[\"cells\"]] == true_cell_names[k])\n",
    "            list_final[[\"score\"]][[n]] = list_final[[\"score\"]][[n]] + 1\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            n = which(list_final[[\"cells\"]] == true_cell_names[k])\n",
    "            list_final[[\"score\"]][[n]] = list_final[[\"score\"]][[n]] - 1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "df_final = as.data.frame(list_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final label for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T12:54:25.091668Z",
     "start_time": "2020-01-28T12:54:26.330Z"
    }
   },
   "outputs": [],
   "source": [
    "                            # Final label for the prediction\n",
    "                            \n",
    "# If the score is negative then the cell was, overall, not correctly classified\n",
    "df_final$result = 0\n",
    "\n",
    "# The true classes of each cell\n",
    "df_final$true = 0\n",
    "for(i in 1:nrow(df_final))\n",
    "{\n",
    "    if(any(grep(\"Gli\", df_final$cells[i])) & df_final$score[i] < 0)\n",
    "    {\n",
    "        df_final$result[i] = \"Ascl1\"\n",
    "        df_final$true[i] = \"Gli1\"\n",
    "    } \n",
    "    else if (any(grep(\"Ascl\", df_final$cells[i])) & df_final$score[i] < 0)\n",
    "    {\n",
    "        df_final$result[i] = \"Gli1\"\n",
    "        df_final$true[i] = \"Ascl1\"\n",
    "    } \n",
    "    else if(any(grep(\"Ascl\", df_final$cells[i])) & df_final$score[i] > 0)\n",
    "    {\n",
    "\n",
    "        df_final$result[i] = \"Ascl1\"\n",
    "        df_final$true[i] = \"Ascl1\"\n",
    "    } \n",
    "    else if(any(grep(\"Gli\", df_final$cells[i])) & df_final$score[i] > 0)\n",
    "    {\n",
    "        df_final$result[i] = \"Gli1\"\n",
    "        df_final$true[i] = \"Gli1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T12:54:27.102962Z",
     "start_time": "2020-01-28T12:54:27.754Z"
    }
   },
   "outputs": [],
   "source": [
    "caret::F_meas(df_final$result %>% as.factor, df_final$true %>% as.factor)\n",
    "caret::recall(df_final$result %>% as.factor, df_final$true %>% as.factor)\n",
    "caret::precision(df_final$result %>% as.factor, df_final$true %>% as.factor)\n",
    "caret::confusionMatrix(df_final$result %>% as.factor, df_final$true %>% as.factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with BMRM package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T15:50:36.004089Z",
     "start_time": "2020-01-28T15:50:35.816Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code for svm_fit and selection of features which best represent the data\n",
    "\n",
    "svm_fit = function(x_training , x_testing , labels , cell_predict , n , LAMBDA) {\n",
    "    \n",
    "    # x_training - data.frame that contains training data\n",
    "    # x_testing - data.frame that contains testing data\n",
    "    # labels - factor containing the labels\n",
    "    # cell_predict - str which indicates which cell to predict\n",
    "    # n - how many genes to use for the final model (this is when one performs gene selection)\n",
    "            #if n = 10(10 negatives and 10 positives)\n",
    "    # LAMBDA - which value of LAMBDA to use\n",
    "    \n",
    "    p = list()\n",
    "    \n",
    "    \n",
    "    # Account for a unbalanced data\n",
    "    if(prop.table(table(labels))[1] != 0.5)\n",
    "    {\n",
    "        loss_weights = ifelse(labels==paste0(cell_predict), sum(labels!=paste0(cell_predict)), sum(labels==paste0(cell_predict)))/length(labels)\n",
    "    } else \n",
    "    {\n",
    "        loss_weights = 0.5\n",
    "    }\n",
    "    \n",
    "    # nrmb Convex and non-convex risk minimization with L2 regularization\n",
    "\n",
    "    loss_function = hingeLoss(as.matrix(x_training), labels == paste0(cell_predict), loss.weights = loss_weights)\n",
    "    w = nrbm(riskFun = loss_function, LAMBDA)\n",
    "    \n",
    "    \n",
    "    # Takes the genes that have higher (abs) w\n",
    "    w_ranked = pmin(rank(+w,ties.method=\"first\"),rank(-w,ties.method=\"first\"))\n",
    "    \n",
    "    # Keep genes which minimize (abs) w more efficiently and do minimization again\n",
    "    x_training_red = x_training[,w_ranked<=n]\n",
    "    loss_function_red = hingeLoss(as.matrix(x_training_red), labels == paste0(cell_predict), loss.weight = loss_weights)\n",
    "    w_reduced = nrbm(riskFun = loss_function_red, LAMBDA)\n",
    "    names(w_reduced) = colnames(x_training_red)\n",
    "    \n",
    "    # Predict\n",
    "    p[[\"prediction\"]] = predict(w_reduced,as.matrix(x_testing[,w_ranked<=n]))\n",
    "    \n",
    "    p[[\"w_reduced\"]] = w_reduced\n",
    "    p[[\"w\"]] = w\n",
    "    \n",
    "    p\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T15:50:37.135295Z",
     "start_time": "2020-01-28T15:50:37.138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cross-validation of the model\n",
    "svm_CV = function(xfolds, x_training ,labels, cell_predict , n ,LAMBDA) {\n",
    "    \n",
    "    # xfolds - how many times to do cross-validation\n",
    "    # x_training - data.frame that contains training data\n",
    "    # labels - vector containing the labels\n",
    "    # cell_predict - str which indicates which cell to predict\n",
    "    # n - how many genes to use for the final model (this is when one performs gene selection)\n",
    "            #if n = 10(10 negatives and 10 positives)\n",
    "    # LAMBDA - which value of LAMBDA to use\n",
    "    \n",
    "    set.seed(1)\n",
    "    \n",
    "    # split all cells into CV xfolds\n",
    "    folds = balanced.cv.fold(labels, xfolds)\n",
    "    \n",
    "    # perform cross-validation\n",
    "    p = lapply(levels(folds),function(x) \n",
    "    {\n",
    "        fit_svm_CV = list()   \n",
    "        # Select the cells for training\n",
    "        training = x_training[folds != x,]\n",
    "        testing = x_training[folds == x,]\n",
    "        labels_CV = labels[folds != x]\n",
    "        true_labels_CV = labels[folds == x]\n",
    "        \n",
    "        # Fit SVM for each CV\n",
    "        fit_svm_CV = svm_fit(x_training = training, x_testing = testing, labels = labels_CV,  cell_predict , n , LAMBDA)\n",
    "        \n",
    "        # Add the true labels of each testing set to the list\n",
    "        #attr(fit_svm_CV, \"true_labels\") = true_labels_CV\n",
    "        fit_svm_CV$true_labels = true_labels_CV\n",
    "\n",
    "        fit_svm_CV\n",
    "        \n",
    "    })\n",
    "    \n",
    "    # Assign the names to the list\n",
    "    y = vector()\n",
    "    n = sapply(seq(1, xfolds,1),  function(x){y = paste0(\"folds_\",x) ; y})\n",
    "    names(p) = n\n",
    "    \n",
    "    p\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:21:29.646498Z",
     "start_time": "2020-01-28T16:06:49.555Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use all data_pred of ascl and gli independently of the day and do random sampling\n",
    "seeds = seq(1,1000,1)\n",
    "\n",
    "# Setup cluster\n",
    "cl = makeCluster(detectCores())\n",
    "\n",
    "                    # Parameters\n",
    "# Folds for cross validation\n",
    "xfolds = 5\n",
    "\n",
    "# Which lambdas (parameter for regularization) to test in CV\n",
    "LAMBDA = c(0.001, 0.05,0.1,0.5,1,2)\n",
    "\n",
    "# Number of genes to take if n = 10(10 negatives and 10 positives)\n",
    "# In this case we just have 9 genes so we take all\n",
    "n_genes = 5\n",
    "\n",
    "cell_predict = \"Gli1\"\n",
    "\n",
    "\n",
    "# Loading all packages necesary | variables | functions\n",
    "invisible(clusterEvalQ(cl, {\n",
    "    library(\"dplyr\")\n",
    "    library(\"bmrm\")\n",
    "    library(\"parallel\")\n",
    "}))\n",
    "clusterExport(cl, c(\"create_dataset_train_test_randomsampling\", \"svm_fit\", \"svm_CV\"), envir = environment())\n",
    "clusterExport(cl, c(\"data\", \"xfolds\",\"LAMBDA\",\"n_genes\", \"cell_predict\"), envir = environment())\n",
    "\n",
    "output_9_genes_svm_bmrm_1000seed = parLapply(cl,seeds, function(seed) {\n",
    "dataset_rf_randomsampling = create_dataset_train_test_randomsampling(data, 0.5, seed, scale = TRUE)\n",
    "\n",
    "    # Scale train and test Data\n",
    "    data_train = dataset_rf_randomsampling$df_train %>% as.data.frame\n",
    "    data_label = dataset_rf_randomsampling$label\n",
    "    data_test = dataset_rf_randomsampling$df_test %>% as.data.frame\n",
    "    result = as.factor(dataset_rf_randomsampling$data_test_result)\n",
    "\n",
    "                        # Test several values of LAMBDA\n",
    "\n",
    "    svm_fit_CV_LAMBDA = lapply(LAMBDA, function(x)\n",
    "    {\n",
    "        svm_fit_CV = svm_CV(xfolds = xfolds ,x_training = data_train, labels = data_label, cell_predict, n = n_genes, LAMBDA = x)\n",
    "        svm_fit_CV\n",
    "        \n",
    "    })\n",
    "\n",
    "    # Assign the names to the list\n",
    "    n = sapply(LAMBDA,  function(x){y = paste0(\"LAMBDA_\",x) ; y})\n",
    "    names(svm_fit_CV_LAMBDA) = n\n",
    "    \n",
    "    \n",
    "                        # Calculate f1_score of different LAMBDA parameters\n",
    "\n",
    "    LAMBDA_acc = sapply(LAMBDA, function(x) {\n",
    "        sapply(seq(1,xfolds,1), function(i) \n",
    "        {\n",
    "            caret::F_meas(svm_fit_CV_LAMBDA[[paste0(\"LAMBDA_\",x)]][[i]]$prediction %>% as.factor, (svm_fit_CV_LAMBDA[[paste0(\"LAMBDA_\",x)]][[i]]$true_labels == \"Gli1\") %>% as.factor)\n",
    "        }) %>% mean\n",
    "    })\n",
    "    names(LAMBDA_acc) = LAMBDA\n",
    "    LAMBDA_acc\n",
    "    \n",
    "                        # Final model, LAMBDA which has highest mean / can be done with sd\n",
    "    \n",
    "    LAMBDA = which.max(LAMBDA_acc) %>% names() %>% as.numeric\n",
    "\n",
    "    svm_model = svm_fit(x_training = data_train, x_testing = data_test, labels = data_label, cell_predict ,n_genes, LAMBDA)\n",
    "\n",
    "                        # Accuracy\n",
    "    metrics = roc.stat(svm_model$prediction, result == cell_predict)\n",
    "    \n",
    "    \n",
    "    y = ifelse(svm_model$prediction == TRUE, paste(cell_predict), data_label[which(!levels(data_label) %in% cell_predict)] %>% paste)\n",
    "    f_meas = caret::F_meas(y %>% as.factor, result %>% as.factor)\n",
    "    \n",
    "    lst = list(model = svm_model,\n",
    "                    eval_metrics = metrics,\n",
    "                    f_score = f_meas,\n",
    "                    result = result,\n",
    "                    pred = y,\n",
    "                    CV = svm_fit_CV_LAMBDA,\n",
    "                    dataset_rf_randomsampling1 = dataset_rf_randomsampling$df_test)\n",
    "    return(lst)\n",
    "})\n",
    "stopCluster(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:41:03.704158Z",
     "start_time": "2020-01-28T16:41:03.622Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy of model\n",
    "mean(map_dbl(seq(1,length(seeds),1), function(x){output_9_genes_svm_bmrm_1000seed[[x]]$eval_metrics$recall[2]}))\n",
    "mean(map_dbl(seq(1,length(seeds),1), function(x){output_9_genes_svm_bmrm_1000seed[[x]]$eval_metrics$precision[2]}))\n",
    "mean(map_dbl(seq(1,length(seeds),1), function(x){output_9_genes_svm_bmrm_1000seed[[x]]$f_score}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:41:13.264794Z",
     "start_time": "2020-01-28T16:41:08.066Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the final Enseble scores over 1000 seeds\n",
    "output_list = output_9_genes_svm_bmrm_1000seed\n",
    "\n",
    "total_cell_names = colnames(data)\n",
    "\n",
    "# Create matrices\n",
    "list_final = list(cells = total_cell_names, score = rep(0, length(total_cell_names)))\n",
    "\n",
    "# add scores (+1) to the cell that was correctly classified and (-1) otherwise\n",
    "# Loop over the seeds\n",
    "for(i in 1:length(seeds))\n",
    "{\n",
    "    true_cell_names = output_list[[i]]$dataset_rf_randomsampling1 %>% rownames \n",
    "    # Loop over each predicted cell in the model\n",
    "    for(k in 1:length(output_list[[i]]$pred))\n",
    "    {\n",
    "        cell_predicted = output_list[[i]]$pred[k]\n",
    "        cell_true = output_list[[i]]$result[k]\n",
    "            \n",
    "        # If the prediction was correct add +1 to score of this cell and -1 otherwise\n",
    "        if(cell_predicted == cell_true)\n",
    "        {\n",
    "            n = which(list_final[[\"cells\"]] == true_cell_names[k])\n",
    "            list_final[[\"score\"]][[n]] = list_final[[\"score\"]][[n]] + 1\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            n = which(list_final[[\"cells\"]] == true_cell_names[k])\n",
    "            list_final[[\"score\"]][[n]] = list_final[[\"score\"]][[n]] - 1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "df_final = as.data.frame(list_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final label predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:41:13.344135Z",
     "start_time": "2020-01-28T16:41:08.068Z"
    }
   },
   "outputs": [],
   "source": [
    "                            # Final label for the prediction\n",
    "                            \n",
    "# If the score is negative then the cell was, overall, not correctly classified\n",
    "df_final$result = 0\n",
    "\n",
    "# The true classes of each cell\n",
    "df_final$true = 0\n",
    "for(i in 1:nrow(df_final))\n",
    "{\n",
    "    if(any(grep(\"Gli\", df_final$cells[i])) & df_final$score[i] < 0)\n",
    "    {\n",
    "        df_final$result[i] = \"Ascl1\"\n",
    "        df_final$true[i] = \"Gli1\"\n",
    "    } \n",
    "    else if (any(grep(\"Ascl\", df_final$cells[i])) & df_final$score[i] < 0)\n",
    "    {\n",
    "        df_final$result[i] = \"Gli1\"\n",
    "        df_final$true[i] = \"Ascl1\"\n",
    "    } \n",
    "    else if(any(grep(\"Ascl\", df_final$cells[i])) & df_final$score[i] > 0)\n",
    "    {\n",
    "\n",
    "        df_final$result[i] = \"Ascl1\"\n",
    "        df_final$true[i] = \"Ascl1\"\n",
    "    } \n",
    "    else if(any(grep(\"Gli\", df_final$cells[i])) & df_final$score[i] > 0)\n",
    "    {\n",
    "        df_final$result[i] = \"Gli1\"\n",
    "        df_final$true[i] = \"Gli1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:41:13.393725Z",
     "start_time": "2020-01-28T16:41:08.070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cells which were wrongly predicted\n",
    "df_final[which(df_final$result != df_final$true),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:41:13.427026Z",
     "start_time": "2020-01-28T16:41:08.072Z"
    }
   },
   "outputs": [],
   "source": [
    "caret::F_meas(df_final$result %>% as.factor, df_final$true %>% as.factor)\n",
    "caret::recall(df_final$result %>% as.factor, df_final$true %>% as.factor)\n",
    "caret::precision(df_final$result %>% as.factor, df_final$true %>% as.factor)\n",
    "caret::confusionMatrix(df_final$result %>% as.factor, df_final$true %>% as.factor)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
